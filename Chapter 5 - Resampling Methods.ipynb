{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Information\n",
    "\n",
    "Resampling methods involve repeatedly drawing samples from a training set and refitting a model on each sample in order to obtain additional information about the fitted model.\n",
    "\n",
    "Two of the most commonly used resampling methods are called **cross-validation** and **bootstrapping**. \n",
    "\n",
    "Cross-validation is used to estimate the test error of a model, in order to evaluate model performance. \n",
    "\n",
    "The bootstrap is used in several contexts, usually to provide a measure of accuracy of a parameter estimate or of a given statistical learning method. \n",
    "\n",
    "## Cross-Validation\n",
    "We estimate the test error rate by holding out a subset of the training observations from the fitting process, and then apply the statistical learning method on those held-out observations.\n",
    "\n",
    "### Validation Set Approach\n",
    "This approach randomly divides the available set of observations into two parts: a training set and a validation set, generally of comparable sizes (eg. 50/50)\n",
    "\n",
    "There are two potential drawbacks\n",
    "1. The validation estimate of the test error rate can be highly variable, depending on precisely which observations are included in the training set and which are included in the validation set\n",
    "2. Since only a subset of the total observations are used to fit the model, the validation set error rate may tend to overestimate the test error rate for the model fit on the entire data set. \n",
    "\n",
    "### Leave-One-Out Cross Validation (LOOCV)\n",
    "Instead of creating two subsets of comparable size, a single observation, $(x_1, y_1)$ is used for the validation set and the remaining observations make up the training set. The mean squared error is given as $MSE_1 = (y_1 - \\hat{y}_1)^2$, which is an estimate for the test error.\n",
    "\n",
    "We can repeat the procedure, by selecting the next point $(x_2, y_2)$ as the validation point, and we repeat until we go through all of the points, generating an MSE for each. The cross-validation estimate of the test MSE is given as: $ CV_{(n)} = \\frac{1}{n}\\sum_{i=1}^{n}MSE_i $\n",
    "\n",
    "LOOCV has far less bias and tends to not overestimate the test error rate. The LOOCV approach will also yield the same results every time. However, it has the potential to be expensive to implement, since the model has to be fit n times. \n",
    "\n",
    "However, the LOOCV for least squares linear or polynomial regression can be computed with the same cost of a single model fit using the following formula:\n",
    "\n",
    "$$ CV_{(n)} = \\frac{1}{n} \\sum_{i=1}^{n}\\Big(\\frac{y_i-\\hat{y}_i}{1-h_i}\\Big)^2 $$\n",
    "\n",
    "where $h_i$ is the leverage of the point, which reflects the amount of influence that an observation has the on overall fit. \n",
    "\n",
    "### k-Fold Cross-Validation\n",
    "This approach involves randomly dividing the set of observations into k groups, or folds, of approximately equal size. \n",
    "\n",
    "The first fold is treated as the validation set, and the method is fit on the remaining $k-1$ folds. $MSE_1$ is then computed on the held-out observations. The process is repeated k times. The k-fold CV estimate is then given as:\n",
    "\n",
    "$$ CV_{(k)} = \\frac{1}{k} \\sum_{i=1}^{k} MSE_i $$\n",
    "\n",
    "LOOCV is thus a special case of k-fold CV where k = n. In practice, k is usually equal to **5 or 10**. \n",
    "\n",
    "#### Bias-Variance Trade-Off for k-Fold Cross-Validation\n",
    "\n",
    "k-fold CV actually tends to give more accurate estimates of the test error rate than LOOCV, since it turns out that LOOCV has higher variance than does k-fold CV. \n",
    "\n",
    "With LOOCV, we're averaging the outputs of n fitted models, which are trained on an almost identical set of observations. Thus, these outputs are highly correlated with each other. With k-fold CV, the training set overlap is smaller, so the outputs are somewhat less correlated with each other. The mean of many highly correlated quantities has higher variance than does the mean of many quantities that are not as highly correlated. \n",
    "\n",
    "We use $k=5$ or $k=10$ because these have been empirically shown to suffer neither from excessively high bias nor from very high variance. \n",
    "\n",
    "### Cross-Validation on Classification Problems\n",
    "Rather than use MSE to quantify test error, we instead just use the number of misclassified observations. \n",
    "\n",
    "$$ CV_{(n)} = \\frac{1}{n} \\sum_{i=1}^n Err_i $$\n",
    "\n",
    "where $Err_i = I(y_i \\ne \\hat{y}_i)$. \n",
    "\n",
    "## The Bootstrap\n",
    "\n",
    "Bootstrapping is any test or metric that relies on random sampling with replacement. The basic idea is to make inference about an estimate for a population parameter using sample data. \n",
    "\n",
    "We randomly select n observations from the data set (where n is equal to the number of observations in the data set) in order to produce a bootstrap data set, $Z^{*1}$. This sampling is performed *with replacement*. We use $Z^{*1}$ to produce a bootstrap estimate of our parameters. For sake of simplicity, let's say there's one parameter $\\alpha$. This process is repeated B times in order to produce B different bootstrap sets, $Z^{*1}, Z^{*2}, ..., Z^{*B}$ and B corresponding parameter estimates, $\\hat{\\alpha}^{*1}, ... \\hat{\\alpha}^{*B}$.\n",
    "\n",
    "You can then do things like obtain a confidence interval for $\\alpha$ or the standard error. The standard error of $\\hat{\\alpha}$ is given by:\n",
    "\n",
    "$$ SE_B(\\hat{\\alpha}) = \\sqrt{\\frac{1}{B-1} \\sum_{r=1}^B \\bigg(\\hat{\\alpha}^{*r} - \\frac{1}{B}\\sum_{r'=1}^B \\hat{\\alpha}^{*r'}\\bigg)^2} $$\n",
    "\n",
    "In the case of model selection, you may want to choose the model that gives the least variance on bootstrapped estimates of the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Cross-Validation and the Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out Cross-Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T16:10:33.403766Z",
     "start_time": "2019-04-01T16:10:33.277722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0         130    3504          12.0    70   \n",
       "1  15.0          8         350.0         165    3693          11.5    70   \n",
       "2  18.0          8         318.0         150    3436          11.0    70   \n",
       "3  16.0          8         304.0         150    3433          12.0    70   \n",
       "4  17.0          8         302.0         140    3449          10.5    70   \n",
       "\n",
       "   origin                       name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(10)\n",
    "auto = pd.read_csv('Data/auto.csv')\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T18:39:55.786867Z",
     "start_time": "2019-04-01T18:39:53.642080Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = auto[['cylinders', 'displacement', 'origin']] \n",
    "y = auto['mpg']\n",
    "\n",
    "# Note that we're not taking advantage of being able to use the leverage to calculate the LOO CV score\n",
    "# But this method will apply to any statistical learning method\n",
    "\n",
    "errors = []\n",
    "for train_index, test_index in LeaveOneOut().split(X):\n",
    "    reg = LinearRegression().fit(X.iloc[train_index], y.iloc[train_index])\n",
    "    mse = mean_squared_error(y.iloc[test_index], reg.predict(X.iloc[test_index]))\n",
    "    errors.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T18:39:56.471245Z",
     "start_time": "2019-04-01T18:39:56.462247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.186778120679175"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOO CV Score\n",
    "np.mean(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T18:39:58.256457Z",
     "start_time": "2019-04-01T18:39:58.158422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.904945665990113"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "errors = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    reg = LinearRegression().fit(X.iloc[train_index], y.iloc[train_index])\n",
    "    mse = mean_squared_error(y.iloc[test_index], reg.predict(X.iloc[test_index]))\n",
    "    errors.append(mse)\n",
    "# The error is higher than the LOOCV error\n",
    "np.mean(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Conceptual\n",
    "\n",
    "1. We now review k-fold cross validation\n",
    "  1. Explain how k-fold cross validation is implemented\n",
    "  2. What are the advantages and disadvantages of k-fold cross-validation relative to: \n",
    "    1. The validation set approach?\n",
    "    2. LOOCV?\n",
    "2. Suppose that we use some statistical learning method to make a prediction for the respone Y for a particular value of the predictor X. Carefully describe how we might estimate the standard deviation of our prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \n",
    "  1. K-Fold CV randomly splits a data set into k groups. The first time you fit the model, you use the first group as the test data and the remaining groups as the training data. The second time, you use the the second group as the test data, and the remaining groups as the training. You continue until you've fitted k models and have made each group the test set. You take the average of the k test scores as the k-fold cross-validation score.\n",
    "  2. \n",
    "    1. The validation set approach may significantly overestimate the test error because it leaves about 50% of the total observations out of the training data. If you have relatively few training observations, this can cause lots of variance in your models and test error scores. K-Fold CV is often done with 5 or 10 folds, meaning either 20% or 10% of the overall data is left out from the training set. \n",
    "    2. LOOCV is more computationally expensive and has a higher variance than K-Folds. \n",
    "2. You can generate B bootstrapped samples of X and Y and fit the model for each sample. You can then get the standard deviation of the predicted Y's from the bootstrapped samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Applied\n",
    "\n",
    "## Default Data Set\n",
    "1. In Chapter 4, we used logistic regression to predict the probability of `default` using `income` and `balance` on the `Default` data set. We will now estimate the test error of this logistic regression model using the validation set approach. \n",
    "  1. Fit a logistic regression model that uses `income` and `balance` to predict `default`\n",
    "  2. Using the validation set approach, estimate the test error of this model. In order to do this, perform the following steps\n",
    "    1. Split the sample set into a training and validation set\n",
    "    2. Fit a multiple logistic regression model using only the training set\n",
    "    3. Obtain a prediction of default status for each individual in the validation set \n",
    "    4. Compute the validation set error\n",
    "  3. Repeat the process in 1b 3 times and comment on the results obtained\n",
    "  4. Now consider a logistic regression model that predicts the probability of `default` using `income`, `balance`, and a dummy variable for `student`. Estimate the test error for this model using the validation set approach. Comment on whether or not including the dummy varaible for `student` leads to a reduction in the test error rate\n",
    "2. Now we'll compute estimates for the standard errors of the `income` and `balance` coefficients in two different ways: using the bootstrap and using the standard formula for computing the standard errors\n",
    "  1. Use the summary function of `statsmodels` to determine the estimated standard errors of the coefficients associated with `income` and `balance`\n",
    "  2. Write a function that takes as input the `Default` data set as well as the index of the observations and that outputs the coefficient estimates for `income` and `balance` in the multiple logistic regression model\n",
    "  3. Estimate the standard errors of the logistic regression coefficients\n",
    "  4. Comment on the estimated standard errors obtained in 1 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:05:11.786871Z",
     "start_time": "2019-04-01T20:05:11.675866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "0      No      No   729.526495  44361.625074\n",
       "1      No     Yes   817.180407  12106.134700\n",
       "2      No      No  1073.549164  31767.138947\n",
       "3      No      No   529.250605  35704.493935\n",
       "4      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "default = pd.read_csv('Data/default.csv')\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:07:57.246139Z",
     "start_time": "2019-04-01T20:07:57.210126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>student_01</th>\n",
       "      <th>default_01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income  student_01  default_01\n",
       "0      No      No   729.526495  44361.625074           0           0\n",
       "1      No     Yes   817.180407  12106.134700           1           0\n",
       "2      No      No  1073.549164  31767.138947           0           0\n",
       "3      No      No   529.250605  35704.493935           0           0\n",
       "4      No      No   785.655883  38463.495879           0           0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default['student_01'] = (default['student'] == 'Yes').astype('int')\n",
    "default['default_01'] = (default['default'] == 'Yes').astype('int')\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:10:10.317111Z",
     "start_time": "2019-04-01T20:10:10.309112Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = default[['balance', 'income']]\n",
    "y = default['default_01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:10:11.701632Z",
     "start_time": "2019-04-01T20:10:11.574634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver='lbfgs')\n",
    "log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:10:13.103151Z",
     "start_time": "2019-04-01T20:10:13.095151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.54047811])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:10:13.821163Z",
     "start_time": "2019-04-01T20:10:13.812661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.64710797e-03, 2.08091984e-05]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:21:42.367997Z",
     "start_time": "2019-04-01T20:21:42.168994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.967, 0.9728, 0.9636]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation Set Cross-Validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(10)\n",
    "scores = []\n",
    "for i in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5)\n",
    "    log_reg = LogisticRegression(solver='lbfgs').fit(X_train, y_train)\n",
    "    scores.append(log_reg.score(X_test, y_test))\n",
    "scores\n",
    "\n",
    "# The scores are actually fairly consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:23:39.571648Z",
     "start_time": "2019-04-01T20:23:39.337646Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9656, 0.966, 0.9654]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the student variable\n",
    "X = default[['balance', 'income', 'student_01']]\n",
    "scores = []\n",
    "for i in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5)\n",
    "    log_reg = LogisticRegression(solver='lbfgs').fit(X_train, y_train)\n",
    "    scores.append(log_reg.score(X_test, y_test))\n",
    "scores\n",
    "\n",
    "# The accuracy is quite similar, just slightly lower on average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:41:37.501936Z",
     "start_time": "2019-04-01T20:41:36.845931Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:42:14.487432Z",
     "start_time": "2019-04-01T20:42:14.250430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>default_01</td>    <th>  No. Observations:  </th>   <td> 10000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9997</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 01 Apr 2019</td> <th>  Pseudo R-squ.:     </th>   <td>0.4594</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:42:14</td>     <th>  Log-Likelihood:    </th>  <td> -789.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -1460.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.541e-292</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393</td> <td>  -10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.06e-05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.14 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:             default_01   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9997\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Mon, 01 Apr 2019   Pseudo R-squ.:                  0.4594\n",
       "Time:                        16:42:14   Log-Likelihood:                -789.48\n",
       "converged:                       True   LL-Null:                       -1460.3\n",
       "                                        LLR p-value:                4.541e-292\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
       "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
       "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = smf.logit(formula='default_01 ~ balance + income', data=default).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:51:52.402405Z",
     "start_time": "2019-04-01T20:51:47.294341Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_params = pd.DataFrame(columns=['Intercept', 'balance', 'income'])\n",
    "\n",
    "for i in range(100):\n",
    "    default_sample = default.sample(frac=0.75, replace=True)\n",
    "    results_sample = smf.logit(formula='default_01 ~ balance + income', data=default_sample).fit(disp=0)\n",
    "    df_params = df_params.append(results_sample.params, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:51:54.919947Z",
     "start_time": "2019-04-01T20:51:54.892444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.001338</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-11.710704</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-11.606816</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11.132899</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11.276914</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-11.656566</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-12.078848</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-12.290239</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-11.193440</td>\n",
       "      <td>0.005407</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-11.002161</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-11.905561</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-12.507011</td>\n",
       "      <td>0.006134</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-11.641727</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-11.788497</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-12.847172</td>\n",
       "      <td>0.006315</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-11.762431</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-11.794191</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-10.750198</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-11.965654</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-10.453901</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-11.904986</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-11.438796</td>\n",
       "      <td>0.005703</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-12.537779</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-11.173079</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-11.174322</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-11.748841</td>\n",
       "      <td>0.005911</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-11.781128</td>\n",
       "      <td>0.005982</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-11.648163</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-10.978720</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-11.996025</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>-11.023296</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-11.729358</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>-11.652051</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-11.367625</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-11.678778</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-11.968811</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-11.044515</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-11.426610</td>\n",
       "      <td>0.005722</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-11.763681</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-12.417842</td>\n",
       "      <td>0.005981</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-12.220201</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>-12.666947</td>\n",
       "      <td>0.006125</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-11.800215</td>\n",
       "      <td>0.005817</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-12.033931</td>\n",
       "      <td>0.006032</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-11.096568</td>\n",
       "      <td>0.005206</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-12.320961</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-11.759288</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-11.875590</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>-11.040996</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-11.467249</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>-11.484558</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-11.880874</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-11.724063</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-12.915352</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-11.654009</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-11.499381</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-11.447183</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-11.453126</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-12.340730</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-11.527898</td>\n",
       "      <td>0.005745</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Intercept   balance    income\n",
       "0  -11.001338  0.005355  0.000018\n",
       "1  -11.710704  0.005735  0.000023\n",
       "2  -11.606816  0.005563  0.000026\n",
       "3  -11.132899  0.005414  0.000019\n",
       "4  -11.276914  0.005341  0.000023\n",
       "5  -11.656566  0.005707  0.000024\n",
       "6  -12.078848  0.006038  0.000018\n",
       "7  -12.290239  0.006007  0.000023\n",
       "8  -11.193440  0.005407  0.000016\n",
       "9  -11.002161  0.005363  0.000017\n",
       "10 -11.905561  0.005789  0.000028\n",
       "11 -12.507011  0.006134  0.000027\n",
       "12 -11.641727  0.005615  0.000022\n",
       "13 -11.788497  0.005844  0.000019\n",
       "14 -12.847172  0.006315  0.000023\n",
       "15 -11.762431  0.005708  0.000023\n",
       "16 -11.794191  0.005682  0.000026\n",
       "17 -10.750198  0.005336  0.000013\n",
       "18 -11.965654  0.005911  0.000023\n",
       "19 -10.453901  0.005090  0.000013\n",
       "20 -11.904986  0.005976  0.000016\n",
       "21 -11.438796  0.005703  0.000016\n",
       "22 -12.537779  0.006135  0.000028\n",
       "23 -11.173079  0.005499  0.000013\n",
       "24 -11.174322  0.005320  0.000021\n",
       "25 -11.748841  0.005911  0.000014\n",
       "26 -11.781128  0.005982  0.000015\n",
       "27 -11.648163  0.005559  0.000025\n",
       "28 -10.978720  0.005168  0.000024\n",
       "29 -11.996025  0.005882  0.000024\n",
       "..        ...       ...       ...\n",
       "70 -11.023296  0.005391  0.000016\n",
       "71 -11.729358  0.005713  0.000020\n",
       "72 -11.652051  0.005689  0.000022\n",
       "73 -11.367625  0.005430  0.000026\n",
       "74 -11.678778  0.005698  0.000024\n",
       "75 -11.968811  0.005772  0.000030\n",
       "76 -11.044515  0.005434  0.000019\n",
       "77 -11.426610  0.005722  0.000014\n",
       "78 -11.763681  0.005661  0.000025\n",
       "79 -12.417842  0.005981  0.000029\n",
       "80 -12.220201  0.005823  0.000033\n",
       "81 -12.666947  0.006125  0.000028\n",
       "82 -11.800215  0.005817  0.000019\n",
       "83 -12.033931  0.006032  0.000017\n",
       "84 -11.096568  0.005206  0.000026\n",
       "85 -12.320961  0.005950  0.000030\n",
       "86 -11.759288  0.005828  0.000019\n",
       "87 -11.875590  0.005951  0.000017\n",
       "88 -11.040996  0.005361  0.000022\n",
       "89 -11.467249  0.005675  0.000019\n",
       "90 -11.484558  0.005520  0.000024\n",
       "91 -11.880874  0.005824  0.000021\n",
       "92 -11.724063  0.005973  0.000010\n",
       "93 -12.915352  0.006390  0.000028\n",
       "94 -11.654009  0.005727  0.000017\n",
       "95 -11.499381  0.005586  0.000025\n",
       "96 -11.447183  0.005567  0.000023\n",
       "97 -11.453126  0.005495  0.000024\n",
       "98 -12.340730  0.005990  0.000025\n",
       "99 -11.527898  0.005745  0.000016\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-01T20:52:11.822668Z",
     "start_time": "2019-04-01T20:52:11.780668Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-11.608120</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498679</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.915352</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-11.906720</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-11.638394</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-11.244482</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-10.453901</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Intercept     balance      income\n",
       "count  100.000000  100.000000  100.000000\n",
       "mean   -11.608120    0.005690    0.000020\n",
       "std      0.498679    0.000283    0.000005\n",
       "min    -12.915352    0.005090    0.000006\n",
       "25%    -11.906720    0.005454    0.000017\n",
       "50%    -11.638394    0.005708    0.000020\n",
       "75%    -11.244482    0.005901    0.000024\n",
       "max    -10.453901    0.006390    0.000033"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bootstrap parameters \n",
    "# The standard deviation is a bit higher in the bootstrapped samples\n",
    "df_params.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Data Set\n",
    "1. We will perform cross-validation on a simulated data set\n",
    "  1. Generated simulated data as follows\n",
    "  ```\n",
    "  np.random.seed(1)\n",
    "  x = np.random.randn(100)\n",
    "  e = np.random.randn(100)\n",
    "  y = x - 2*x**2 + e\n",
    "  ```\n",
    "  What is n and what is p? Write out the equation form\n",
    "  2. Create a scatterplot of X against Y\n",
    "  3. Set a random seed and then compute the LOOCV errors that result from fitting the following four models using least squares:\n",
    "    1. $ Y = \\beta_0 + \\beta_1X + \\epsilon $\n",
    "    2. $ Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\epsilon $\n",
    "    3. $ Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\epsilon $\n",
    "    4. $ Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta+3X^3 + \\beta_4X^4 + \\epsilon$\n",
    "  4. Repeat c) with another random seed and report your results\n",
    "  5. Which of the models in c) had the lowest LOOCV error? Is this what you expected?\n",
    "  6. Comment on the statistical significance of the coefficient estimates that resulted from fitting each of the models. Do these results agree with conclusions drawn based on the cross-validation results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:51:31.429793Z",
     "start_time": "2019-04-03T16:51:31.386787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(100)\n",
    "e = np.random.randn(100)\n",
    "y = x - 2*x**2 + e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have n = 100 and p = 1. \n",
    "$$ \\beta_0 = 0 $$\n",
    "$$ \\beta_1 = 1 $$\n",
    "$$ \\beta_2 = -2 $$\n",
    "$$ \\beta_3 = \\beta_4 = 0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:54:32.935322Z",
     "start_time": "2019-04-03T16:54:30.072582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFJCAYAAABKLF7JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMgAABiCQAQAwwP8HyWVqt1CD7GgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20905944588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T17:58:07.500914Z",
     "start_time": "2019-04-03T17:58:07.406891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b0</th>\n",
       "      <th>x</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.624345</td>\n",
       "      <td>2.638498</td>\n",
       "      <td>4.285832</td>\n",
       "      <td>6.961671</td>\n",
       "      <td>-4.099779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.611756</td>\n",
       "      <td>0.374246</td>\n",
       "      <td>-0.228947</td>\n",
       "      <td>0.140060</td>\n",
       "      <td>-0.135741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.528172</td>\n",
       "      <td>0.278965</td>\n",
       "      <td>-0.147342</td>\n",
       "      <td>0.077822</td>\n",
       "      <td>-0.682611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.072969</td>\n",
       "      <td>1.151262</td>\n",
       "      <td>-1.235268</td>\n",
       "      <td>1.325403</td>\n",
       "      <td>-2.781913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865408</td>\n",
       "      <td>0.748930</td>\n",
       "      <td>0.648130</td>\n",
       "      <td>0.560897</td>\n",
       "      <td>-1.727365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    b0         x        x2        x3        x4         y\n",
       "0  1.0  1.624345  2.638498  4.285832  6.961671 -4.099779\n",
       "1  1.0 -0.611756  0.374246 -0.228947  0.140060 -0.135741\n",
       "2  1.0 -0.528172  0.278965 -0.147342  0.077822 -0.682611\n",
       "3  1.0 -1.072969  1.151262 -1.235268  1.325403 -2.781913\n",
       "4  1.0  0.865408  0.748930  0.648130  0.560897 -1.727365"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(np.array([np.ones(len(x)), x, x**2, x**3, x**4, y]).T, columns = ['b0', 'x', 'x2', 'x3', 'x4', 'y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T18:04:29.125921Z",
     "start_time": "2019-04-03T18:04:29.118922Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T18:09:00.030699Z",
     "start_time": "2019-04-03T18:08:59.579625Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.57424533508528"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "errors = []\n",
    "X = df[['b0', 'x']]\n",
    "for train_index, test_index in LeaveOneOut().split(X):\n",
    "    reg = LinearRegression().fit(X.iloc[train_index], y[train_index])\n",
    "    mse = mean_squared_error(y[test_index], reg.predict(X.iloc[test_index]))\n",
    "    errors.append(mse)\n",
    "np.mean(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T18:09:01.776853Z",
     "start_time": "2019-04-03T18:09:01.284227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7233222659285132"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "errors = []\n",
    "X = df[['b0', 'x', 'x2']]\n",
    "for train_index, test_index in LeaveOneOut().split(X):\n",
    "    reg = LinearRegression().fit(X.iloc[train_index], y[train_index])\n",
    "    mse = mean_squared_error(y[test_index], reg.predict(X.iloc[test_index]))\n",
    "    errors.append(mse)\n",
    "np.mean(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T18:09:06.126018Z",
     "start_time": "2019-04-03T18:09:05.620979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.252326733018285"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "errors = []\n",
    "X = df[['b0', 'x2', 'x3']]\n",
    "for train_index, test_index in LeaveOneOut().split(X):\n",
    "    reg = LinearRegression().fit(X.iloc[train_index], y[train_index])\n",
    "    mse = mean_squared_error(y[test_index], reg.predict(X.iloc[test_index]))\n",
    "    errors.append(mse)\n",
    "np.mean(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T18:09:16.293971Z",
     "start_time": "2019-04-03T18:09:15.885370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.40683427704436"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "errors = []\n",
    "X = df[['b0', 'x2', 'x3', 'x4']]\n",
    "for train_index, test_index in LeaveOneOut().split(X):\n",
    "    reg = LinearRegression().fit(X.iloc[train_index], y[train_index])\n",
    "    mse = mean_squared_error(y[test_index], reg.predict(X.iloc[test_index]))\n",
    "    errors.append(mse)\n",
    "np.mean(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the errors are minimized with $ Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\epsilon $, which is the true model\n",
    "\n",
    "If we run this again with a different seed, the results will be the exact same since it evaluates all possible combinations with 1 test observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T18:21:26.543670Z",
     "start_time": "2019-04-03T18:21:26.438145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 03 Apr 2019</td> <th>  Prob (F-statistic):</th>  <td>0.00209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:21:26</td>     <th>  Log-Likelihood:    </th> <td> -228.87</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   461.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   466.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -1.4131</td> <td>    0.242</td> <td>   -5.849</td> <td> 0.000</td> <td>   -1.893</td> <td>   -0.934</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    0.8610</td> <td>    0.272</td> <td>    3.162</td> <td> 0.002</td> <td>    0.321</td> <td>    1.401</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>37.310</td> <th>  Durbin-Watson:     </th> <td>   1.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  69.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.554</td> <th>  Prob(JB):          </th> <td>8.01e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.651</td> <th>  Cond. No.          </th> <td>    1.15</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.093\n",
       "Model:                            OLS   Adj. R-squared:                  0.083\n",
       "Method:                 Least Squares   F-statistic:                     9.997\n",
       "Date:                Wed, 03 Apr 2019   Prob (F-statistic):            0.00209\n",
       "Time:                        14:21:26   Log-Likelihood:                -228.87\n",
       "No. Observations:                 100   AIC:                             461.7\n",
       "Df Residuals:                      98   BIC:                             466.9\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -1.4131      0.242     -5.849      0.000      -1.893      -0.934\n",
       "x              0.8610      0.272      3.162      0.002       0.321       1.401\n",
       "==============================================================================\n",
       "Omnibus:                       37.310   Durbin-Watson:                   1.661\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               69.521\n",
       "Skew:                          -1.554   Prob(JB):                     8.01e-16\n",
       "Kurtosis:                       5.651   Cond. No.                         1.15\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's run this model with statsmodels so we can see statistical significance\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "results = smf.ols('y ~ x', data = df).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T18:22:56.874063Z",
     "start_time": "2019-04-03T18:22:56.809992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   304.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 03 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>1.47e-42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:22:56</td>     <th>  Log-Likelihood:    </th> <td> -134.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   274.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    97</td>      <th>  BIC:               </th> <td>   282.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1350</td> <td>    0.115</td> <td>    1.169</td> <td> 0.245</td> <td>   -0.094</td> <td>    0.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    1.0936</td> <td>    0.107</td> <td>   10.229</td> <td> 0.000</td> <td>    0.881</td> <td>    1.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>   -1.9846</td> <td>    0.085</td> <td>  -23.331</td> <td> 0.000</td> <td>   -2.153</td> <td>   -1.816</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.893</td> <th>  Durbin-Watson:     </th> <td>   2.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.640</td> <th>  Jarque-Bera (JB):  </th> <td>   0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.170</td> <th>  Prob(JB):          </th> <td>   0.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.132</td> <th>  Cond. No.          </th> <td>    2.10</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.863\n",
       "Model:                            OLS   Adj. R-squared:                  0.860\n",
       "Method:                 Least Squares   F-statistic:                     304.9\n",
       "Date:                Wed, 03 Apr 2019   Prob (F-statistic):           1.47e-42\n",
       "Time:                        14:22:56   Log-Likelihood:                -134.42\n",
       "No. Observations:                 100   AIC:                             274.8\n",
       "Df Residuals:                      97   BIC:                             282.7\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1350      0.115      1.169      0.245      -0.094       0.364\n",
       "x              1.0936      0.107     10.229      0.000       0.881       1.306\n",
       "x2            -1.9846      0.085    -23.331      0.000      -2.153      -1.816\n",
       "==============================================================================\n",
       "Omnibus:                        0.893   Durbin-Watson:                   2.152\n",
       "Prob(Omnibus):                  0.640   Jarque-Bera (JB):                0.552\n",
       "Skew:                          -0.170   Prob(JB):                        0.759\n",
       "Kurtosis:                       3.132   Cond. No.                         2.10\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# both x and x2 are statistically significant, as expected\n",
    "results = smf.ols('y ~ x + x2', data = df).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:14:32.473164Z",
     "start_time": "2019-04-03T19:14:32.425170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   204.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 03 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>1.40e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:14:32</td>     <th>  Log-Likelihood:    </th> <td> -133.66</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   275.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    96</td>      <th>  BIC:               </th> <td>   285.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.1280</td> <td>    0.115</td> <td>    1.111</td> <td> 0.269</td> <td>   -0.101</td> <td>    0.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    0.9065</td> <td>    0.187</td> <td>    4.842</td> <td> 0.000</td> <td>    0.535</td> <td>    1.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>   -1.9753</td> <td>    0.085</td> <td>  -23.187</td> <td> 0.000</td> <td>   -2.144</td> <td>   -1.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>        <td>    0.0788</td> <td>    0.065</td> <td>    1.216</td> <td> 0.227</td> <td>   -0.050</td> <td>    0.208</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.539</td> <th>  Durbin-Watson:     </th> <td>   2.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.463</td> <th>  Jarque-Bera (JB):  </th> <td>   1.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.236</td> <th>  Prob(JB):          </th> <td>   0.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.193</td> <th>  Cond. No.          </th> <td>    5.53</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.865\n",
       "Model:                            OLS   Adj. R-squared:                  0.861\n",
       "Method:                 Least Squares   F-statistic:                     204.8\n",
       "Date:                Wed, 03 Apr 2019   Prob (F-statistic):           1.40e-41\n",
       "Time:                        15:14:32   Log-Likelihood:                -133.66\n",
       "No. Observations:                 100   AIC:                             275.3\n",
       "Df Residuals:                      96   BIC:                             285.7\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.1280      0.115      1.111      0.269      -0.101       0.357\n",
       "x              0.9065      0.187      4.842      0.000       0.535       1.278\n",
       "x2            -1.9753      0.085    -23.187      0.000      -2.144      -1.806\n",
       "x3             0.0788      0.065      1.216      0.227      -0.050       0.208\n",
       "==============================================================================\n",
       "Omnibus:                        1.539   Durbin-Watson:                   2.129\n",
       "Prob(Omnibus):                  0.463   Jarque-Bera (JB):                1.081\n",
       "Skew:                          -0.236   Prob(JB):                        0.583\n",
       "Kurtosis:                       3.193   Cond. No.                         5.53\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x3 is not statistically significant\n",
    "results = smf.ols('y ~ x + x2 + x3', data=df).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:14:04.127003Z",
     "start_time": "2019-04-03T19:14:04.082376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   163.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 03 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>1.24e-41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:14:04</td>     <th>  Log-Likelihood:    </th> <td> -130.63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   271.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    95</td>      <th>  BIC:               </th> <td>   284.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.3140</td> <td>    0.136</td> <td>    2.311</td> <td> 0.023</td> <td>    0.044</td> <td>    0.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    0.9127</td> <td>    0.183</td> <td>    4.999</td> <td> 0.000</td> <td>    0.550</td> <td>    1.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>   -2.5445</td> <td>    0.248</td> <td>  -10.264</td> <td> 0.000</td> <td>   -3.037</td> <td>   -2.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>        <td>    0.0992</td> <td>    0.064</td> <td>    1.556</td> <td> 0.123</td> <td>   -0.027</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>        <td>    0.1394</td> <td>    0.057</td> <td>    2.437</td> <td> 0.017</td> <td>    0.026</td> <td>    0.253</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.537</td> <th>  Durbin-Watson:     </th> <td>   2.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.464</td> <th>  Jarque-Bera (JB):  </th> <td>   1.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.238</td> <th>  Prob(JB):          </th> <td>   0.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.184</td> <th>  Cond. No.          </th> <td>    15.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.873\n",
       "Model:                            OLS   Adj. R-squared:                  0.867\n",
       "Method:                 Least Squares   F-statistic:                     163.0\n",
       "Date:                Wed, 03 Apr 2019   Prob (F-statistic):           1.24e-41\n",
       "Time:                        15:14:04   Log-Likelihood:                -130.63\n",
       "No. Observations:                 100   AIC:                             271.3\n",
       "Df Residuals:                      95   BIC:                             284.3\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.3140      0.136      2.311      0.023       0.044       0.584\n",
       "x              0.9127      0.183      4.999      0.000       0.550       1.275\n",
       "x2            -2.5445      0.248    -10.264      0.000      -3.037      -2.052\n",
       "x3             0.0992      0.064      1.556      0.123      -0.027       0.226\n",
       "x4             0.1394      0.057      2.437      0.017       0.026       0.253\n",
       "==============================================================================\n",
       "Omnibus:                        1.537   Durbin-Watson:                   2.100\n",
       "Prob(Omnibus):                  0.464   Jarque-Bera (JB):                1.088\n",
       "Skew:                          -0.238   Prob(JB):                        0.581\n",
       "Kurtosis:                       3.184   Cond. No.                         15.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# however, x4 is statistically significant\n",
    "# perhaps there is some overfitting\n",
    "results = smf.ols('y ~ x + x2 + x3 + x4', data = df).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Data Set\n",
    "\n",
    "1. \n",
    "  1. Based on this data set, provide an estimate for the population mean of `medv`, call it $\\hat{\\mu}$\n",
    "  2. Provide an estimate of the standard error $\\hat{\\mu}$. Hint: The standard error can be given by dividing the sample standard deviation by the square root of the number of observations\n",
    "  3. Now estimate the standard error of $\\hat{\\mu}$ using the bootstrap. How does it compare to the answer from b?\n",
    "  4. Based on the bootstrap estimate from c, provide a 95% confidence interval for the mean of `medv`. Hint, you can use $[\\hat{\\mu} - 2SE(\\hat{\\mu}), \\hat{\\mu}+2SE(\\hat{\\mu})]$. \n",
    "  5. Based on the data, provide an estimate $\\hat{\\mu}_{med}$ for the median value of `medv` of the population\n",
    "  6. Estimate the standard error of the median using the bootstrap. \n",
    "  7. Based on this data set, provide an estimate for the 10th percentile of `medv`. Call this quantity $\\hat{\\mu}_{0.1}$\n",
    "  8. Use the bootstrap to estimate the standard error of $\\hat{\\mu}_{0.1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:32:21.909606Z",
     "start_time": "2019-04-03T19:32:21.875610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.read_csv('Data/boston.csv')\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:32:56.392244Z",
     "start_time": "2019-04-03T19:32:56.382250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.532806324110698"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['medv'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:33:35.745960Z",
     "start_time": "2019-04-03T19:33:35.735961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4088611474975351"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard Error\n",
    "boston['medv'].std() / np.sqrt(boston.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:41:32.913905Z",
     "start_time": "2019-04-03T19:41:32.529799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4171312611340175"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bootstrap standard error\n",
    "# 1000 is pretty standard for # of bootstrap samples\n",
    "means = [boston['medv'].sample(n=len(boston), replace=True).mean() for i in range(1000)]\n",
    "np.std(means)\n",
    "# the bootstrapped standard error is pretty close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:42:51.024833Z",
     "start_time": "2019-04-03T19:42:51.015832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.698543801842664"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5%\n",
    "\n",
    "boston['medv'].mean() - 2*np.std(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:43:04.043563Z",
     "start_time": "2019-04-03T19:43:04.034544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.367068846378732"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 95%\n",
    "\n",
    "boston['medv'].mean() + 2*np.std(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:43:19.482119Z",
     "start_time": "2019-04-03T19:43:19.474123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['medv'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:44:08.537934Z",
     "start_time": "2019-04-03T19:44:08.172310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3694604038323996"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians = [boston['medv'].sample(n=len(boston), replace=True).median() for i in range (1000)]\n",
    "np.std(medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:44:25.407113Z",
     "start_time": "2019-04-03T19:44:25.386599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.75"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['medv'].quantile(0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T19:47:43.378415Z",
     "start_time": "2019-04-03T19:47:41.715788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51466376402463"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles = [boston['medv'].sample(n=len(boston), replace=True).quantile(0.10) for i in range(1000)]\n",
    "np.std(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
